{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copyright-protected material, all rights reserved. (c) University of Vienna.\n",
    "_Copyright Notice of the corresponding course at Moodle applies. <br> Only to be used in the MRE course._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MRE Assignment 3 - Digital Video Processing\n",
    "In this assignment, you will use OpenCV and FFmpeg to implement very basic video editing functions. These tasks include:\n",
    "\n",
    "1. Create a slide show (as a video) from images, and optionally create the slideshow as greyscale video.\n",
    "2. Extract the audio track from a video file.\n",
    "3. Replace the audio track in a video file.\n",
    "4. Combine two or more videos into one video file.\n",
    "5. Blend an image (fade-in/fade-out) with a video.\n",
    "6. Blend two videos into one video (video collage).\n",
    "\n",
    "In this notebook, you will implement your solution. This notebook will be imported into the \"*_def.ipynb\" notebook.\n",
    "\n",
    "Of course you can include code for testing your implementation in this implementation notebook, but code for testing and output generated for testing is not going to be assessed.\n",
    "\n",
    "Of course, your code for the solutions in this notebook will be inspected and is subject to grading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "For general installation instructions, please refer to the ressources given for all the assignments [in Moodle](https://moodle.univie.ac.at/course/view.php?id=164140#section-12).\n",
    "\n",
    "If the cell below executes without error, you can start the assignment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- Imports --------\n",
    "# Please do not change the contents of this cell!\n",
    "\n",
    "# Imports required by us.\n",
    "import cv2              # opencv-python\n",
    "import ffmpeg           # ffmpeg-python\n",
    "import subprocess   # for calling local executables such as ffmpeg.exe\n",
    "import pandas as pd  # pandas\n",
    "from fractions import Fraction as frac # simplifying fractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cells below, place your own imports, global variables, (helper) functions and classes. Feel free to add cells here as you see fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place your own imports here.\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import IPython\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place any helper functions, global variables and classes here.\n",
    "\n",
    "# For example:the function you need to play back a mp4-video file.\n",
    "# You may use this function to display the videos in your definition file during the assessment for demoing the solutions.\n",
    "def VideoPlayer(videoFile: str) -> None:\n",
    "    \n",
    "    IPython.display.display(\n",
    "        HTML(\"\"\"\n",
    "            <video alt=\"test\" controls>\n",
    "            <source src={} type=\"video/mp4\">\n",
    "            </video>\n",
    "        \"\"\".format(videoFile))\n",
    "    )\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VideoPlayer(\"./resources/video/sample1.mp4\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3.1: Create a slide show (Video) from multiple images and convert it to greyscale "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://learnopencv.com/read-write-and-display-a-video-using-opencv-cpp-python/\n",
    "# https://docs.opencv.org/4.x/dd/d9e/classcv_1_1VideoWriter.html\n",
    "\n",
    "def CreateVideoFromImages(inImgLibFolder, imageFormat, durationInSec, convertToGreyScale, outFolder, outVideo):\n",
    "    if not os.path.exists(outFolder):\n",
    "        os.makedirs(outFolder)\n",
    "    outputFilepath = os.path.join(outFolder, outVideo)\n",
    "    \n",
    "    # OpenCV VideoWriter with MP4 and 1280x720\n",
    "    # Duration established with framerate\n",
    "    videoWriter = cv2.VideoWriter(outputFilepath, cv2.VideoWriter_fourcc('m','p','4','v'), 1/durationInSec, (1280, 720))\n",
    "    \n",
    "    if os.path.isdir(inImgLibFolder):\n",
    "        for filename in os.listdir(inImgLibFolder):\n",
    "            filepath = os.path.join(inImgLibFolder, filename)\n",
    "            name, extension = os.path.splitext(filename)\n",
    "            if os.path.isfile(filepath) and extension.upper() in [('.' + imageFormat.upper())]: #just take these extensions:\n",
    "                \n",
    "                # Read Image\n",
    "                img = cv2.imread(filepath)\n",
    "                \n",
    "                # Resize to fit\n",
    "                img = cv2.resize(img, (1280, 720)) \n",
    "                \n",
    "                # Greyscale\n",
    "                if convertToGreyScale:\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) # grey\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB) # and back to RGB\n",
    "                \n",
    "                # Append to videoWriter\n",
    "                videoWriter.write(img)\n",
    "    \n",
    "    videoWriter.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CreateVideoFromImages(\"./task1/images/\", \"JPG\", 2, True, \"./task1/output/\", \"outTask1Video.mp4\")\n",
    "# VideoPlayer(\"./task1/output/outTask1Video.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3.2: Extract the Audio Track from a Video File "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from my MRS Assignment 2\n",
    "# https://superuser.com/questions/268985/remove-audio-from-video-file-with-ffmpeg\n",
    "\n",
    "def SplitAudioVideoTracks(inVideo, outFolder, outVideoTrack, outAudioTrack) -> None:\n",
    "    if not os.path.exists(outFolder):\n",
    "        os.makedirs(outFolder)\n",
    "    outAudioFilepath = os.path.join(outFolder, outAudioTrack)\n",
    "    outVideoFilepath = os.path.join(outFolder, outVideoTrack)\n",
    "    \n",
    "    # extract wav with ffmpeg\n",
    "    subprocess.run(['ffmpeg', '-i', inVideo, '-acodec' ,'pcm_s16le', '-y', outAudioFilepath])#, stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT) # hidden output\n",
    "    \n",
    "    # copy video w_o_ audio with ffmpeg\n",
    "    # -an for no audio\n",
    "    subprocess.run(['ffmpeg', '-i', inVideo, '-c' ,'copy', '-an', '-y', outVideoFilepath])#, stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SplitAudioVideoTracks(\"./resources/video/sample1.mp4\", \"./task2/output/\", \"outTask2VideoTrack.mp4\", \"outTask2AudioTrack.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3.3: Replace the Audio Track in a Video File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://superuser.com/questions/1137612/ffmpeg-replace-audio-in-video\n",
    "\n",
    "def AddOrReplaceAudio(inVideo, inAudio, outFolder, outVideo) -> None:\n",
    "    if not os.path.exists(outFolder):\n",
    "        os.makedirs(outFolder)\n",
    "    outVideoFilepath = os.path.join(outFolder, outVideo)\n",
    "    \n",
    "    # copy video\n",
    "    # map input audio as audiostream\n",
    "# \"-shortest\" parameter\n",
    "    subprocess.run(['ffmpeg', '-i', inVideo, '-i', inAudio, '-c:v' ,'copy', '-map', '0:v:0', '-map', '1:a:0', '-shortest', '-y', outVideoFilepath])#, stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AddOrReplaceAudio(\"./resources/video/sample1.mp4\", \"./resources/audio/Amazon.mp3\", \"./task3/output/\", \"outTask3Video.mp4\")\n",
    "# VideoPlayer(\"./task3/output/outTask3Video.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3.4: Combine Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.opencv.org/4.x/d4/d15/group__videoio__flags__base.html\n",
    "# https://stackoverflow.com/questions/61659346/how-to-get-4-character-codec-code-for-videocapture-object-in-opencv\n",
    "# https://ffmpeg.org/ffprobe.html\n",
    "# https://stackoverflow.com/questions/73142995/trying-to-fetch-all-audio-streams-with-ffmpeg-python\n",
    "\n",
    "def VideoMetadataExtractor(inVideoLibFolder) -> pd.DataFrame:\n",
    "    dataFrame = pd.DataFrame(columns=['filename', 'vCodec', 'vcodecID', 'vDur', 'vFPS', 'vHeight', 'vWidth', 'aCodec', 'acodecID', 'aChannels', 'aSamplerate', 'aBitrate'])\n",
    "    \n",
    "    if os.path.isdir(inVideoLibFolder):\n",
    "        for filename in sorted(os.listdir(inVideoLibFolder)):\n",
    "            filepath = os.path.join(inVideoLibFolder, filename)\n",
    "            name, extension = os.path.splitext(filename)\n",
    "            if os.path.isfile(filepath):# and extension.upper() in ['.MP4']:\n",
    "                \n",
    "                # Video with OpenCV\n",
    "                videoCapture = cv2.VideoCapture(filepath)\n",
    "                vcodecID = int(videoCapture.get(cv2.CAP_PROP_FOURCC))\n",
    "                vCodec = vcodecID.to_bytes(4, byteorder=sys.byteorder).decode() # codecID is hex for the four-character-code\n",
    "                vFPS = videoCapture.get(cv2.CAP_PROP_FPS)\n",
    "                vDur = videoCapture.get(cv2.CAP_PROP_FRAME_COUNT) / vFPS\n",
    "                vHeight = videoCapture.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "                vWidth = videoCapture.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "                \n",
    "                # Audio with FFProbe\n",
    "                probe = ffmpeg.probe(filepath)\n",
    "                audioStream = None\n",
    "                for stream in probe['streams']:\n",
    "                    if stream['codec_type'] == 'audio':\n",
    "                        audioStream = stream\n",
    "                        break\n",
    "                \n",
    "                newRow = pd.DataFrame.from_records([{\n",
    "                    'filename': filename,\n",
    "                    'vCodec': vCodec,\n",
    "                    'vcodecID': vcodecID,\n",
    "                    'vDur': vDur,\n",
    "                    'vFPS': vFPS,\n",
    "                    'vHeight': vHeight,\n",
    "                    'vWidth': vWidth,\n",
    "                    'aCodec': audioStream['codec_name'],\n",
    "                    'acodecID': audioStream['codec_tag_string'],\n",
    "                    'aChannels': int(audioStream['channels']),\n",
    "                    'aSamplerate': int(audioStream['sample_rate']),\n",
    "                    'aBitrate': int(audioStream['bit_rate'])\n",
    "                }])\n",
    "                dataFrame = pd.concat([dataFrame, newRow])\n",
    "                \n",
    "    dataFrame.reset_index(drop=True, inplace=True)\n",
    "    return dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(VideoMetadataExtractor(\"./resources/video/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://creatomate.com/blog/how-to-join-multiple-videos-into-one-using-ffmpeg\n",
    "#https://ffmpeg.org/ffmpeg-filters.html#concat\n",
    "#https://superuser.com/questions/1806388/ffmpeg-error-input-link-parameters-do-not-match-the-corresponding-output-link-pa\n",
    "\n",
    "def CombineVideos(inVideoLibFolder, outFolder, outVideo) -> None:\n",
    "    if not os.path.exists(outFolder):\n",
    "        os.makedirs(outFolder)\n",
    "    outVideoFilepath = os.path.join(outFolder, outVideo)\n",
    "    \n",
    "    # initialize ffmpeg command\n",
    "    cmd = ['ffmpeg']\n",
    "    numberVideos = 0\n",
    "    \n",
    "    if os.path.isdir(inVideoLibFolder):\n",
    "        for filename in sorted(os.listdir(inVideoLibFolder)):\n",
    "            filepath = os.path.join(inVideoLibFolder, filename)\n",
    "            name, extension = os.path.splitext(filename)\n",
    "            if os.path.isfile(filepath):# and extension.upper() in ['.MP4']:\n",
    "                numberVideos += 1\n",
    "                cmd.append('-i')\n",
    "                cmd.append(filepath)\n",
    "    \n",
    "    \n",
    "    # here, the complex filter is manually created\n",
    "    cmd.append('-filter_complex')\n",
    "    filter = ''\n",
    "    for i in range(0, numberVideos):\n",
    "        x = '['+str(i)+':v]scale=1280:720[v'+str(i)+'];' #scaling all videos to same size (and given a new name)\n",
    "        filter += x\n",
    "    for i in range(0, numberVideos):\n",
    "        x = '[v' + str(i) + '][' + str(i) + ':a]' #appending all streams to complex filter\n",
    "        filter += x\n",
    "    filter += 'concat=n=' + str(numberVideos) + ':v=1:a=1' #adding the concat, n, and outputstreams\n",
    "    cmd.append(filter)\n",
    "    \n",
    "    cmd.append('-vsync')\n",
    "    cmd.append('vfr')\n",
    "    cmd.append('-y')\n",
    "    cmd.append(outVideoFilepath)\n",
    "     \n",
    "    print(cmd)\n",
    "    subprocess.run(cmd)#, stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CombineVideos(\"./resources/video/\", \"./task4/output/\", \"outTask4.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3.5: Blend an Image in a Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when i remove the fade, the picture shows\n",
    "# the picture just wont show with the fade.....\n",
    "\n",
    "#https://ffmpeg.org/ffmpeg-filters.html\n",
    "\n",
    "def AddFadingImage(inVideo, inImg, time, outFolder, outVideo) -> None:\n",
    "    p = 1 #fade-duration\n",
    "    totalDuration = 2 * p + time\n",
    "    \n",
    "    if not os.path.exists(outFolder):\n",
    "        os.makedirs(outFolder)\n",
    "    outVideoFilepath = os.path.join(outFolder, outVideo)\n",
    "    \n",
    "    cmd = ['ffmpeg']\n",
    "    cmd.append('-i')\n",
    "    cmd.append(inVideo)\n",
    "    cmd.append('-i')\n",
    "    cmd.append(inImg)\n",
    "    \n",
    "    cmd.append('-filter_complex')\n",
    "    \n",
    "    filter  = f'[0:v]scale=1280:720[vid];' #scale video\n",
    "    filter += f'[1:v]scale=1280:720,' #scale\n",
    "    filter += f'fade=t=in:st=0:d={p}:alpha=1,' #fade in\n",
    "    filter += f'fade=t=out:st={time + p}:d={p}:alpha=1[img];' #fade out image\n",
    "    filter += f\"[vid][img]overlay=0:0:enable='between(t,0,{totalDuration})'\" #only enable overlay in this time\n",
    "    cmd.append(filter)\n",
    "    \n",
    "    cmd.append('-y')\n",
    "    cmd.append(outVideoFilepath)\n",
    "     \n",
    "    print(cmd)\n",
    "    subprocess.run(cmd)#, stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AddFadingImage(\"./resources/video/sample2.mp4\", \"./resources/images/elephant14m.JPG\", 2, \"./task5/output/\", \"outTask5.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3.6: Create a Video Collage - blend two videos into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.baeldung.com/linux/ffmpeg-stitch-videos-horizontally\n",
    "\n",
    "def VideoClipMixer(inVideo1, inVideo2, layout, outFolder, outVideo) -> None: \n",
    "    if not os.path.exists(outFolder):\n",
    "        os.makedirs(outFolder)\n",
    "    outVideoFilepath = os.path.join(outFolder, outVideo)\n",
    "    \n",
    "    cmd = ['ffmpeg']\n",
    "    cmd.append('-i')\n",
    "    cmd.append(inVideo1)\n",
    "    cmd.append('-i')\n",
    "    cmd.append(inVideo2)\n",
    "    \n",
    "    cmd.append('-filter_complex')\n",
    "    \n",
    "    if layout == 'column':\n",
    "        filter  = f'[0:v]scale=1280:720/2[v1];'\n",
    "        filter += f'[1:v]scale=1280:720/2[v2];'\n",
    "        filter += f\"[v1][v2]vstack\"\n",
    "        cmd.append(filter)\n",
    "        \n",
    "    if layout == 'row':\n",
    "        filter  = f'[0:v]scale=1280/2:720[v1];'\n",
    "        filter += f'[1:v]scale=1280/2:720[v2];'\n",
    "        filter += f\"[v1][v2]hstack\"\n",
    "        cmd.append(filter)\n",
    "        \n",
    "    cmd.append('-vsync')\n",
    "    cmd.append('vfr')\n",
    "    cmd.append('-shortest')\n",
    "    cmd.append('-y')\n",
    "    cmd.append(outVideoFilepath)\n",
    "     \n",
    "    print(cmd)\n",
    "    subprocess.run(cmd)#, stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VideoClipMixer(\"./resources/video/sample2.mp4\", \"./resources/video/sample3.avi\", 'row', \"./task6/output/\", \"outTask6.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
