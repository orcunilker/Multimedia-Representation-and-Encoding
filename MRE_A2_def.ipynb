{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copyright-protected material, all rights reserved. (c) University of Vienna.\n",
    "_Copyright Notice of the corresponding course at Moodle applies. <br> Only to be used in the MRE course._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MRE Assignment 2 - Digital Audio Processing \n",
    "\n",
    "In this assignment you will load, decode, and process digital audio files (e.g., MP3, WAV) using Python. For the following tasks, you will use our suggested libraries (see the setup section). For both audio formats you will extract and process content and some basic metadata. For the following tasks, you will use our suggested libraries. \n",
    "\n",
    "In this notebook, you find the detailed specification. For assessment of your solution you are expected to demonstrate your implementation and answer questions in mostly textual form here.\n",
    "\n",
    "‚ùó **Note:** Please make sure that all potential errors, including handling files, paths, and run-time errors are handled properly (e.g., useful error messages to users)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import your implementation\n",
    "\n",
    "Import the corresponding Jupyter Notebook named \"*_impl.ipynb\" for this assignment here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%run MRE_A2_impl.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.1 Organize Audio files by specific criteria (35P):\n",
    "\n",
    "\n",
    "\n",
    "Write a Python function MyAudioFilesOrganizer using mutagen and Wave libraries (Mutagen: https://mutagen.readthedocs.io/en/latest/) so that:\n",
    "- One can call it with two parameters, i.e., an input directory path and an enum representing the grouping criteria (the grouping criteria enum can be the artist, the album, or the genre).\n",
    "- The function lists the audio files in the directory grouped by the provided criteria. The list should also disply the following columns (if available from the source, probably in a specific format mentioned): \n",
    "  - artist (string)\n",
    "  - album (string)\n",
    "  - genre (string)\n",
    "  - filename (string)\n",
    "  - format (string)\n",
    "  - duration (float)\n",
    "  - title (string)\n",
    "  - date (string)\n",
    "  - sample rate (integer)\n",
    "  - bitrate (integer)\n",
    "  - track (string)\n",
    "  - composer (string)\n",
    "  - encoder (string)\n",
    "  \n",
    "- The function returns a pandas DataFrame that can be displayed. The DataFrame represents a table with the columns mentioned above.\n",
    "\n",
    "**Example:**<br>\n",
    "\n",
    "input = `./media/audio/`, `Criteria.ARTIST`<br>\n",
    "Function call: `MyAudioFilesOrganizer(\"./media/audio/\", Criteria.ARTIST)`\n",
    "<br>\n",
    "<br>\n",
    "The result might look like this:<br>\n",
    "![SampleTable](./A2T3_sampleTable.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstrate your implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate your implementation here.\n",
    "# Only enter the calls to your functions here so you can demonstrate validity of your solution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.2: Audio mixer (25P):\n",
    "\n",
    "Write a Python function `TwoAudioMixer` using `ffmpeg` so that:\n",
    "- One can call it with the parameters as below: \n",
    "  - audio file 1\n",
    "  - start in seconds\n",
    "  - end in seconds\n",
    "  - audio file 2\n",
    "  - start in seconds\n",
    "  - end in seconds\n",
    "  - overlapDur\n",
    "  - outputDir\n",
    "  - outputFilename\n",
    "  <br>\n",
    "Where start and end in seconds specify the part of the audio file to be mixed, i.e., start and end. The transition from audio 1 to audio 2 should overlap as specified by the input parameter overlap duration.\n",
    "\t\n",
    "**Example:**\n",
    "Function call: `TwoAudioMixer('../a1.mp3', 0, 6, '../a2.mp3', 0, 6, 2, \"output-a2\", \"t2-mixed.mp3\")`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstrate your implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate your implementation here. \n",
    "# Only enter the calls to your functions here so you can demonstrate validity of your solution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.3: Concealing speakers ID by lowering/increasing the audio pitch (20P):\n",
    "\n",
    "Write a Python function VoicePitchChanger so that:\n",
    "- One can call it with four parameters: \n",
    "  - audio file 1\n",
    "  - shift degree: e.g., -5 to 5\n",
    "  - outputDir\n",
    "  - outputFilename\n",
    "- Try to reverse the result by providing the output file to your function.\n",
    "- Note that the length of the audio file should not be affected by the pitch change.\n",
    "\n",
    "**Example:**\n",
    "Function call: `VoicePitchChanger('../a1.mp3', 1.5, \"output-a2\", \"t3-pitched.mp3\")`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstrate your implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate your implementation here.\n",
    "# Only enter the calls to your functions here so you can demonstrate validity of your solution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.4: Theoretical part (20P):\n",
    "\n",
    "Answer the following questions in written form:\n",
    "\n",
    "- How is the volume (i.e., how loud a sound is) reflected in analog and digital audio signals? <br><br>\n",
    "        The higher the amplitude of the function, the louder the audio signal is. <br>\n",
    "        But 'loudness' can also be a property of human conception. For example, when an audio signal is 'louder', so the function has a bigger amplitude over time, the human percieve the sound as louder than just a short loud sound. But also, the human doesn't percieve all frenquecies in the same way. Some frequencies are louder for humans although they are played with the same 'amplitude' as other frequencies.<br>\n",
    "        In streaming services such as Spotify, this knowledge is used to analyse the songs and adjust them accordingly.\n",
    "  \n",
    "- Why does it make sense to perform non-uniform quantization?<br><br>\n",
    "        For example, when a signal is very quiet, in uniform quantization, most of the bits remain unused. Space can therefore be saved. <br>\n",
    "        Moreover, as in some parts bits can be saved, quantization-levels can be denser in densly distributed regions of the sample-levels. <br>\n",
    "        Non-uniform quantization allows for the encoder to adjust the density of quantization to the audio signal, compressing more efficiently.\n",
    "\n",
    "- What is Pulse Code Modulation (PCM)?<br><br>\n",
    "        PCM is a conventional way of turning an analog signal into a digital signal.<br>\n",
    "        It takes the value of an analog signal with a samplerate (e.g. 96khz) and specific a bit-depth (e.g. 16bits).<br>\n",
    "        The sample-rate determines the highest possible frequency in the signal, the bit-depth determines the Signal-to-Noise-Ratio.<br>\n",
    "        For example, the PCM properties of Audio-CDs are 44.1khz and 16bits, which allows for a very high quality representation of an audio signal.<br>\n",
    "\n",
    "- Why do WAV files require more storage space than MP3 files?<br><br>\n",
    "        WAV-files store PCM signals, totally uncompressed. As there is a lot of potential for compression, it takes a lot of space.<br>\n",
    "        MP3 uses several compression techniques. <br>\n",
    "        Firstly, it uses psychoacoustical compression techniques, which eliminate elements of the signal a usual human being just can't hear.<br>\n",
    "        Additionally, it uses entropy encoding.<br>\n",
    "\n",
    "- Describe the physical appearance of sound and how it is converted to digitally sampled audio. Explain how sampling works and the meaning of the terms amplitude, sampling frequency, and quantization.<br><br>\n",
    "        I'll add to the above description of mine.<br>\n",
    "        Sound describes air-pressure waves in the air, travelling into our ears.\n",
    "        The change in air-pressure over time (at a perciever) represents the analog sound signal.<br>\n",
    "        To convert this to digital audio, microphones can record the changes in air-pressures. We can use the signal coming from the microphone as an analog signal<br>\n",
    "        As we want to save digitally, we have to convert it to digital audio, which happens in PCM.<br>\n",
    "        It looks into the analog signal with the sample-rate and for every time-step, it puts the sample on the matching level provided by the bit-depth, which is called quantization.<br>\n",
    "        It quantizes the sample, as it is not possible to save the amplitude in a continuos matter.\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
